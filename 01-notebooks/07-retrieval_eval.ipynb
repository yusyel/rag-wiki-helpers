{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs_with_q_4o-mini.json\", \"rt\") as f_in:\n",
    "    docs_4o_mini = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs_with_q_lama.json\", \"rt\") as f_in:\n",
    "    docs_llama = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/.local/share/virtualenvs/proje-m46awf8E/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_mini_lm = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "model_distilbert = SentenceTransformer(\"multi-qa-distilbert-cos-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenv_mini = len(model_mini_lm.encode(\"test\"))\n",
    "lenv_distilbert = len(model_distilbert.encode(\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.reddit.com/r/germany/wiki/autobahn_safety',\n",
       " 'content': 'The Autobahn is a [network of interstate highways in Germany](https://en.m.wikipedia.org/wiki/Autobahn#/media/File%3AAutobahnen_in_Deutschland.svg) with a total length of more than 8,000 miles. [65%](https://en.wikipedia.org/wiki/Autobahn#Speed_limits) of the Autobahn has no speed limit. How safe can that be?\\nVehicles traveled 147 billion miles on the Autobahn in 2015. 322 people died = 2.19 deaths per billion miles.\\nIn the US, vehicles travelled 757 billion miles on interstate highways. 3,837 people died = 5.07 deaths per billion miles.\\nThat means: If you drive on the interstate, your likelihood to die is 131% higher than for the same distance on the Autobahn.\\n*sources:*\\nStatistisches Bundesamt: [Unfallentwicklung auf deutschen Stra√üen 2015](https://www.destatis.de/DE/PresseService/Presse/Pressekonferenzen/2016/Unfallentwicklung_2015/Pressebroschuere_unfallentwicklung.pdf?__blob=publicationFile)\\nNational Highway Traffic Safety Administration: [Fatal Crashes by STATE and Road Function Class 2015](https://www-fars.nhtsa.dot.gov/)\\nU. S. Department of Transportation: [Traffic Volume Trends December 2015](https://www.fhwa.dot.gov/policyinformation/travel_monitoring/15dectvt/15dectvt.pdf)',\n",
       " 'headline': 'How safe is the Autobahn?',\n",
       " 'id': '9d8370cf-a2c8-4c54-9f9c-476b9c09a933',\n",
       " 'length': 1202,\n",
       " 'question': 'What are the safety statistics comparing the Autobahn to US interstate highways?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_4o_mini[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_sett(v):\n",
    "\n",
    "    index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"source\": {\"type\": \"text\"},\n",
    "                \"content\": {\"type\": \"text\"},\n",
    "                \"headline\": {\"type\": \"text\"},\n",
    "                \"id\": {\"type\": \"keyword\"},\n",
    "                \"length\": {\"type\": \"integer\"},\n",
    "                \"question\": {\"type\": \"text\"},\n",
    "                \"question_vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": v,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\"\n",
    "                },\n",
    "                \"content_vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": v,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\"\n",
    "                },\n",
    "                \"question_content_vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": v,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\"\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return index_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = {\n",
    "    \"model\": {\n",
    "        model_mini_lm:lenv_mini,\n",
    "        model_distilbert :lenv_distilbert,\n",
    "\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"docs_4o_mini\": docs_4o_mini,\n",
    "        \"docs_llama\" : docs_llama\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'384_docs_4o_mini'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = emb[\"dataset\"]\n",
    "\"384_docs_4o_mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['docs_4o_mini', 'docs_llama'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[\"dataset\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Key: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      "), Model Value: 384, Dataset: docs_4o_mini\n",
      "Model Key: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      "), Model Value: 384, Dataset: docs_llama\n",
      "Model Key: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      "), Model Value: 768, Dataset: docs_4o_mini\n",
      "Model Key: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      "), Model Value: 768, Dataset: docs_llama\n"
     ]
    }
   ],
   "source": [
    "models = list(emb[\"model\"].items())\n",
    "datasets = list(emb[\"dataset\"].items())\n",
    "\n",
    "for (model_key, model_value), (dataset_key, dataset_value) in product(models, datasets):\n",
    "    print(f\"Model Key: {model_key}, Model Value: {model_value}, Dataset: {dataset_key}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384_docs_4o_mini 384\n",
      "384_docs_llama 384\n",
      "768_docs_4o_mini 768\n",
      "768_docs_llama 768\n"
     ]
    }
   ],
   "source": [
    "for (model_key, model_value), (dataset_key, dataset_value) in product(models, datasets):\n",
    "\n",
    "    index_name = f\"{str(model_value)}_{dataset_key}\"\n",
    "    settings = index_sett(model_value)\n",
    "    print(index_name, model_value)\n",
    "    es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "    es_client.indices.create(index=index_name, body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.reddit.com/r/germany/wiki/autobahn_safety',\n",
       " 'content': 'The Autobahn is a [network of interstate highways in Germany](https://en.m.wikipedia.org/wiki/Autobahn#/media/File%3AAutobahnen_in_Deutschland.svg) with a total length of more than 8,000 miles. [65%](https://en.wikipedia.org/wiki/Autobahn#Speed_limits) of the Autobahn has no speed limit. How safe can that be?\\nVehicles traveled 147 billion miles on the Autobahn in 2015. 322 people died = 2.19 deaths per billion miles.\\nIn the US, vehicles travelled 757 billion miles on interstate highways. 3,837 people died = 5.07 deaths per billion miles.\\nThat means: If you drive on the interstate, your likelihood to die is 131% higher than for the same distance on the Autobahn.\\n*sources:*\\nStatistisches Bundesamt: [Unfallentwicklung auf deutschen Stra√üen 2015](https://www.destatis.de/DE/PresseService/Presse/Pressekonferenzen/2016/Unfallentwicklung_2015/Pressebroschuere_unfallentwicklung.pdf?__blob=publicationFile)\\nNational Highway Traffic Safety Administration: [Fatal Crashes by STATE and Road Function Class 2015](https://www-fars.nhtsa.dot.gov/)\\nU. S. Department of Transportation: [Traffic Volume Trends December 2015](https://www.fhwa.dot.gov/policyinformation/travel_monitoring/15dectvt/15dectvt.pdf)',\n",
       " 'headline': 'How safe is the Autobahn?',\n",
       " 'id': '9d8370cf-a2c8-4c54-9f9c-476b9c09a933',\n",
       " 'length': 1202,\n",
       " 'question': 'What are the safety statistics comparing the Autobahn to US interstate highways?'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_4o_mini[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_doc(model_key, dataset):\n",
    "    for doc in tqdm(dataset):\n",
    "        question = doc[\"question\"]\n",
    "        content = doc[\"content\"]\n",
    "        qt = question + ' ' + content\n",
    "        doc[\"question_vector\"] = model_key.encode(question)\n",
    "        doc[\"content_vector\"] = model_key.encode(content)\n",
    "        doc[\"question_content_vector\"] = model_key.encode(qt)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[See also this thread for more information on \"du\" and \"Sie\"](https://www.reddit.com/r/AskAGerman/comments/rsb0xu/is_there_a_moment_when_a_new_friendwork_colleague/).\n"
     ]
    }
   ],
   "source": [
    "print(docs_llama[395][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docs_llama'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actions(index_name, data):\n",
    "    for i, record in enumerate(data):\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": i,\n",
    "            \"_source\": record,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b0cb1850754ae99b1b39486004beb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(661, [])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_doc(model_mini_lm, docs_4o_mini)\n",
    "actions = generate_actions(index_name=\"384_docs_4o_mini\", data=docs_4o_mini)\n",
    "helpers.bulk(es_client, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46010afad3044a282eb1edaef9b972f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(661, [])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_doc(model_mini_lm, docs_llama)\n",
    "actions = generate_actions(index_name=\"384_docs_llama\", data=docs_llama)\n",
    "helpers.bulk(es_client, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b20447504ad45af8f89af644196ee48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(661, [])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_doc(model_distilbert, docs_4o_mini)\n",
    "actions = generate_actions(index_name=\"768_docs_4o_mini\", data=docs_4o_mini)\n",
    "helpers.bulk(es_client, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58087867b4841d3a5e4102bb4d2aeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(661, [])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_doc(model_distilbert, docs_llama)\n",
    "actions = generate_actions(index_name=\"768_docs_llama\", data=docs_llama)\n",
    "helpers.bulk(es_client, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the total length of the Autobahn network in Germany?',\n",
       " 'headline': 'How safe is the Autobahn?',\n",
       " 'content': '9d8370cf-a2c8-4c54-9f9c-476b9c09a933'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth = pd.read_csv(\"gp4o-mini-questions.csv\")\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, index_name):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"content\", \"headline\", \"question\", \"source\", \"length\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function, model, index_name):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q[\"content\"]\n",
    "        results = search_function(q, model, index_name)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_vector_knn(q, model, index_name):\n",
    "    question = q['question']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_vector', v_q, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384_docs_4o_mini 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665005aab0db4fb784c390a9e8db0636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.822087745839637, 'mrr': 0.6860010085728689} 384_docs_4o_mini\n",
      "384_docs_llama 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0911ee496945a8b8517fbd3d4f0192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.822087745839637, 'mrr': 0.6860010085728689} 384_docs_llama\n",
      "768_docs_4o_mini 768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a64810191844a8e934a1f372523cd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8311649016641453, 'mrr': 0.6961018658598076} 768_docs_4o_mini\n",
      "768_docs_llama 768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8dbe822fb64c22990ad3f91d8412b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8311649016641453, 'mrr': 0.6961018658598076} 768_docs_llama\n"
     ]
    }
   ],
   "source": [
    "for (model_key, model_value), (dataset_key, dataset_value) in product(models, datasets):\n",
    "    index_name = f\"{model_value}_{dataset_key}\"\n",
    "    print(index_name, model_value)\n",
    "    print(evaluate(ground_truth, question_vector_knn, model_key, index_name), index_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_vector_knn(q, model, index_name):\n",
    "    question = q['question']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn(\"content_vector\", v_q, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0d932de78245bd9d2d3d7255ecc187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8717095310136157, 'mrr': 0.717297024710035} 384_docs_4o_mini\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff81ca7c9a54c96923a9ca933ec6a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8720121028744326, 'mrr': 0.7173726676752392} 384_docs_llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e4c28945e24f729a955f5d2575ca1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8925869894099848, 'mrr': 0.7341805345436204} 768_docs_4o_mini\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faab9519eeec43dc96044b08781ed2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8925869894099848, 'mrr': 0.7341805345436204} 768_docs_llama\n"
     ]
    }
   ],
   "source": [
    "for (model_key, model_value), (dataset_key, dataset_value) in product(models, datasets):\n",
    "    index_name = f\"{model_value}_{dataset_key}\"\n",
    "    print(evaluate(ground_truth, content_vector_knn, model_key, index_name), index_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_vector_knn(q, model, index_name):\n",
    "    question = q['question']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn(\"question_content_vector\", v_q, index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1323b77d94fa4a48a69475e402995de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.9128593040847202, 'mrr': 0.7873424104891578} 384_docs_4o_mini\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e02cfb36fc1456a90e296b425afddc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.9131618759455371, 'mrr': 0.787418053454362} 384_docs_llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9542b5645004ec08d72b1faa2a61cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.9231467473524962, 'mrr': 0.7947503782148263} 768_docs_4o_mini\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fc173876dc47dfb409fb6fced37591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.9228441754916793, 'mrr': 0.7948562783661121} 768_docs_llama\n"
     ]
    }
   ],
   "source": [
    "for (model_key, model_value), (dataset_key, dataset_value) in product(models, datasets):\n",
    "    index_name = f\"{model_value}_{dataset_key}\"\n",
    "    print(evaluate(ground_truth, question_text_vector_knn, model_key, index_name), index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proje-m46awf8E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
