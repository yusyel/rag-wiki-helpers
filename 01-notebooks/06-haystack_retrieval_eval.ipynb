{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs_with_q_4o-mini.json\", \"rt\") as f_in:\n",
    "    ds_gpt = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.reddit.com/r/germany/wiki/autobahn_safety',\n",
       " 'content': 'The Autobahn is a [network of interstate highways in Germany](https://en.m.wikipedia.org/wiki/Autobahn#/media/File%3AAutobahnen_in_Deutschland.svg) with a total length of more than 8,000 miles. [65%](https://en.wikipedia.org/wiki/Autobahn#Speed_limits) of the Autobahn has no speed limit. How safe can that be?\\nVehicles traveled 147 billion miles on the Autobahn in 2015. 322 people died = 2.19 deaths per billion miles.\\nIn the US, vehicles travelled 757 billion miles on interstate highways. 3,837 people died = 5.07 deaths per billion miles.\\nThat means: If you drive on the interstate, your likelihood to die is 131% higher than for the same distance on the Autobahn.\\n*sources:*\\nStatistisches Bundesamt: [Unfallentwicklung auf deutschen Straßen 2015](https://www.destatis.de/DE/PresseService/Presse/Pressekonferenzen/2016/Unfallentwicklung_2015/Pressebroschuere_unfallentwicklung.pdf?__blob=publicationFile)\\nNational Highway Traffic Safety Administration: [Fatal Crashes by STATE and Road Function Class 2015](https://www-fars.nhtsa.dot.gov/)\\nU. S. Department of Transportation: [Traffic Volume Trends December 2015](https://www.fhwa.dot.gov/policyinformation/travel_monitoring/15dectvt/15dectvt.pdf)',\n",
       " 'headline': 'How safe is the Autobahn?',\n",
       " 'id': '9d8370cf-a2c8-4c54-9f9c-476b9c09a933',\n",
       " 'length': 1202,\n",
       " 'question': 'What are the safety statistics comparing the Autobahn to US interstate highways?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_gpt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'Genealogy',\n",
       " 'question': 'I/my ancestors was/were denationalized by the National Socialists. Can I get my German citizenship back?',\n",
       " 'content': 'Yes, victims of National Socialist denationalization measures and their descendants have the right to be renationalized in line with Article 116 (2) of the Basic Law even if this means multiple nationality. There is no need to prove knowledge of the German language. Nevertheless it is examined whether the German nationality of the ancestor could have been lost for reasons unrelated to National Socialism. Were this the case, the descendants would have no right to German citizenship. [source](http://www.auswaertiges-amt.de/sid_8102715B432128CA20217EC07AF2F4C5/EN/Infoservice/FAQ/Staatsangehoerigkeit/16-Ausbuergerung.html?nn=479790)',\n",
       " 'length': 1279,\n",
       " 'source': 'https://www.reddit.com/r/germany/wiki/faq',\n",
       " 'id': '97272d36-c1aa-4e30-806b-af47423bf325'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_gpt[660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.reddit.com/r/germany/wiki/health_insurance',\n",
       " 'content': 'There are no co-payments for minors under 18 years. The co-payments for adults:\\n* Seeing a doctor in their office: free\\n* Emergency room: free\\n* Hospital stay: 10 € per day for the first 28 days per calendar year, free after that\\n* Ambulance ride: 10 €\\n* Prescription drugs and prescribed medical aids (e.g. wheelchair, hearing aid): Between 5 and 10 euro per prescription.\\n* Additional dental co-payments: Nothing if you earn less than 1,190 euro per month. If you earn more: 50% for tooth implants and permanent dentures. If you go to a dentist every year for 5 years your co-payment drops to 40%, after 10 years to 35%.\\nAll regular co-payments by you and your spouse combined in one year cannot exceed 2% of your combined gross income in that year. If you have a chronic illness, the cap is 1%.',\n",
       " 'headline': 'Co-payments',\n",
       " 'id': '2e394391-1ac9-4040-bfb4-31c5c992f454',\n",
       " 'length': 797,\n",
       " 'question': 'What are the co-payment amounts for adults regarding hospital stays and prescription drugs?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_gpt[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs_with_q_lama.json\", \"rt\") as f_in:\n",
    "    ds_llama = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = ds_llama[:47] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = ds_llama[47:661]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_llama = part1 + part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.reddit.com/r/germany/wiki/autobahn_safety',\n",
       " 'content': 'The Autobahn is a [network of interstate highways in Germany](https://en.m.wikipedia.org/wiki/Autobahn#/media/File%3AAutobahnen_in_Deutschland.svg) with a total length of more than 8,000 miles. [65%](https://en.wikipedia.org/wiki/Autobahn#Speed_limits) of the Autobahn has no speed limit. How safe can that be?\\nVehicles traveled 147 billion miles on the Autobahn in 2015. 322 people died = 2.19 deaths per billion miles.\\nIn the US, vehicles travelled 757 billion miles on interstate highways. 3,837 people died = 5.07 deaths per billion miles.\\nThat means: If you drive on the interstate, your likelihood to die is 131% higher than for the same distance on the Autobahn.\\n*sources:*\\nStatistisches Bundesamt: [Unfallentwicklung auf deutschen Straßen 2015](https://www.destatis.de/DE/PresseService/Presse/Pressekonferenzen/2016/Unfallentwicklung_2015/Pressebroschuere_unfallentwicklung.pdf?__blob=publicationFile)\\nNational Highway Traffic Safety Administration: [Fatal Crashes by STATE and Road Function Class 2015](https://www-fars.nhtsa.dot.gov/)\\nU. S. Department of Transportation: [Traffic Volume Trends December 2015](https://www.fhwa.dot.gov/policyinformation/travel_monitoring/15dectvt/15dectvt.pdf)',\n",
       " 'headline': 'How safe is the Autobahn?',\n",
       " 'id': '9d8370cf-a2c8-4c54-9f9c-476b9c09a933',\n",
       " 'length': 1202,\n",
       " 'question': 'What are the safety statistics comparing the Autobahn to US interstate highways?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_llama[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'Genealogy',\n",
       " 'question': 'I/my ancestors was/were denationalized by the National Socialists. Can I get my German citizenship back?',\n",
       " 'content': 'Yes, victims of National Socialist denationalization measures and their descendants have the right to be renationalized in line with Article 116 (2) of the Basic Law even if this means multiple nationality. There is no need to prove knowledge of the German language. Nevertheless it is examined whether the German nationality of the ancestor could have been lost for reasons unrelated to National Socialism. Were this the case, the descendants would have no right to German citizenship. [source](http://www.auswaertiges-amt.de/sid_8102715B432128CA20217EC07AF2F4C5/EN/Infoservice/FAQ/Staatsangehoerigkeit/16-Ausbuergerung.html?nn=479790)',\n",
       " 'length': 1279,\n",
       " 'source': 'https://www.reddit.com/r/germany/wiki/faq',\n",
       " 'id': '97272d36-c1aa-4e30-806b-af47423bf325'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_llama[660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.reddit.com/r/germany/wiki/health_insurance',\n",
       " 'content': 'There are no co-payments for minors under 18 years. The co-payments for adults:\\n* Seeing a doctor in their office: free\\n* Emergency room: free\\n* Hospital stay: 10 € per day for the first 28 days per calendar year, free after that\\n* Ambulance ride: 10 €\\n* Prescription drugs and prescribed medical aids (e.g. wheelchair, hearing aid): Between 5 and 10 euro per prescription.\\n* Additional dental co-payments: Nothing if you earn less than 1,190 euro per month. If you earn more: 50% for tooth implants and permanent dentures. If you go to a dentist every year for 5 years your co-payment drops to 40%, after 10 years to 35%.\\nAll regular co-payments by you and your spouse combined in one year cannot exceed 2% of your combined gross income in that year. If you have a chronic illness, the cap is 1%.',\n",
       " 'headline': 'Co-payments',\n",
       " 'id': '2e394391-1ac9-4040-bfb4-31c5c992f454',\n",
       " 'length': 797,\n",
       " 'question': 'What are the co-payment amounts for adults regarding hospital stays and prescription drugs?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_llama[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_docs(prepared_docs, docs):\n",
    "    for ds in docs:\n",
    "        prepared_docs.append(\n",
    "            Document(content=ds[\"content\"], meta={\"source\": ds[\"source\"], \"headline\": ds[\"headline\"], \"ids\": ds[\"id\"], \"length\":ds[\"length\"], \"question\": ds[\"question\"]})\n",
    "        )\n",
    "    return prepared_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchEmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_document_store(model, docs, index_name):\n",
    "    document_store = ElasticsearchDocumentStore(hosts = \"http://localhost:9200\", embedding_similarity_function=\"cosine\", index=index_name)\n",
    "    document_embedder = SentenceTransformersDocumentEmbedder(model=model,\n",
    "                                                         meta_fields_to_embed=[\"headline\", \"question\"])\n",
    "    document_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "    indexing = Pipeline()\n",
    "    indexing.add_component(instance=document_embedder, name=\"document_embedder\")\n",
    "    indexing.add_component(instance=document_writer, name=\"document_writer\")\n",
    "    indexing.connect(\"document_embedder.documents\", \"document_writer.documents\")\n",
    "    indexing.run({\"document_embedder\": {\"documents\": docs}}),\n",
    "    return document_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_retrieval_pipeline(model, document_store):\n",
    "    retrieval_pipeline = Pipeline()\n",
    "    retrieval_pipeline.add_component(\"text_embedder\", SentenceTransformersTextEmbedder(model=model, progress_bar=False))\n",
    "    retrieval_pipeline.add_component(\"retriever\", ElasticsearchEmbeddingRetriever(document_store=document_store, top_k=5))\n",
    "    retrieval_pipeline.connect(\"text_embedder\", \"retriever\")\n",
    "    return retrieval_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_csv(\"gp4o-mini-questions.csv\")\n",
    "ground_truth = df_ground_truth.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the total length of the Autobahn network in Germany?',\n",
       " 'headline': 'How safe is the Autobahn?',\n",
       " 'content': '9d8370cf-a2c8-4c54-9f9c-476b9c09a933'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ground_truth_docs(docs):\n",
    "    ground_truth_docs = []\n",
    "    for doc in docs:\n",
    "        ground_truth_docs.append(\n",
    "            [Document(content=doc[\"content\"]), Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"])])\n",
    "        ground_truth_docs.append(\n",
    "            [Document(content=doc[\"content\"]), Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"])])\n",
    "        ground_truth_docs.append(\n",
    "            [Document(content=doc[\"content\"]), Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"])])\n",
    "        ground_truth_docs.append(\n",
    "            [Document(content=doc[\"content\"]), Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"])])\n",
    "        ground_truth_docs.append(\n",
    "            [Document(content=doc[\"content\"]), Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"]),Document(content=doc[\"content\"])])\n",
    "        \n",
    "    return ground_truth_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_retrieved_docs(retrieval_pipeline):\n",
    "    retrieved_docs = []\n",
    "    for q in tqdm(ground_truth):\n",
    "        question = q[\"question\"]\n",
    "        result = retrieval_pipeline.run({\"text_embedder\": {\"text\": question}})\n",
    "        retrieved_docs.append([result[\"retriever\"][\"documents\"][0], result[\"retriever\"][\"documents\"][1], result[\"retriever\"][\"documents\"][2] ,result[\"retriever\"][\"documents\"][3], result[\"retriever\"][\"documents\"][4]])\n",
    "    return retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.evaluators import DocumentMRREvaluator, DocumentRecallEvaluator, DocumentMAPEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eval():\n",
    "    eval_pipe = Pipeline()\n",
    "    eval_pipe.add_component(\"doc_mrr_evaluator\", DocumentMRREvaluator())\n",
    "    eval_pipe.add_component(\"doc_rec_evaluator\", DocumentRecallEvaluator())\n",
    "    eval_pipe.add_component(\"map\", DocumentMAPEvaluator())\n",
    "    return eval_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data, model, index_name):\n",
    "    prepared_docs = []\n",
    "    docs = prepare_docs(prepared_docs, data)\n",
    "    document_store = prepare_document_store(model=model, docs=docs, index_name=index_name)\n",
    "    retrieval_pipeline = prepare_retrieval_pipeline(model=model, document_store=document_store)\n",
    "    ground_truth_docs = prepare_ground_truth_docs(ds_gpt)\n",
    "    retrieved_docs = prepare_retrieved_docs(retrieval_pipeline)\n",
    "    eval_pipe = prepare_eval()\n",
    "    results = eval_pipe.run(\n",
    "        {\n",
    "            \"doc_mrr_evaluator\": {\n",
    "                \"ground_truth_documents\": ground_truth_docs,\n",
    "                \"retrieved_documents\": retrieved_docs,\n",
    "            },\n",
    "            \"doc_rec_evaluator\": {\n",
    "                \"ground_truth_documents\": ground_truth_docs,\n",
    "                \"retrieved_documents\": retrieved_docs,\n",
    "            },\n",
    "            \"map\": {\n",
    "                \"ground_truth_documents\": ground_truth_docs,\n",
    "                \"retrieved_documents\": retrieved_docs,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dicts = {\n",
    "    \"models\": {\n",
    "        \"model_mini_lm\": \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\",\n",
    "        \"model_distilbert\": \"sentence-transformers/multi-qa-distilbert-cos-v1\"\n",
    "\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"docs_4o_mini\": ds_gpt,\n",
    "        \"docs_llama\" : ds_llama\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Key: model_mini_lm, Model Value: sentence-transformers/multi-qa-MiniLM-L6-cos-v1, Dataset: docs_4o_mini\n",
      "model_mini_lm_docs_4o_mini\n",
      "Model Key: model_mini_lm, Model Value: sentence-transformers/multi-qa-MiniLM-L6-cos-v1, Dataset: docs_llama\n",
      "model_mini_lm_docs_llama\n",
      "Model Key: model_distilbert, Model Value: sentence-transformers/multi-qa-distilbert-cos-v1, Dataset: docs_4o_mini\n",
      "model_distilbert_docs_4o_mini\n",
      "Model Key: model_distilbert, Model Value: sentence-transformers/multi-qa-distilbert-cos-v1, Dataset: docs_llama\n",
      "model_distilbert_docs_llama\n"
     ]
    }
   ],
   "source": [
    "models = list(run_dicts[\"models\"].items())\n",
    "datasets = list(run_dicts[\"datasets\"].items())\n",
    "\n",
    "for (model_key, model_value), (dataset_key, dataset_value) in product(models, datasets):\n",
    "    print(f\"Model Key: {model_key}, Model Value: {model_value}, Dataset: {dataset_key}\")\n",
    "    index_name = f\"{model_key}_{dataset_key}\"\n",
    "    print(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61fb0f7d8b24ca7bddfc9213708d210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6050b63eeedf4ec287275287504d3742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed57d664d8f44df998e3150e6ece4c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbf495246134ec994e22b0c02180580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40480a5d3ad543cb91cb6340d534ad51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748e00aa6d714d178c4771e3f0f71788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141d4b150c644a96bfa115c1987a1fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bf32b708ad4e999bc68e6b3d5cd7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (model_key, model_value), (dataset_key, dataset_value) in product(models, datasets):\n",
    "    model = model_value\n",
    "    dataset = dataset_value\n",
    "    dataset_name = dataset_key\n",
    "    index_name = f\"{model_key}_{dataset_key}\"\n",
    "    results = run(data=dataset, model=model, index_name=index_name)\n",
    "\n",
    "    results_dict[index_name]= {}\n",
    "    for evaluator in results:\n",
    "        results_dict[index_name][evaluator] = results[evaluator][\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mini_lm_docs_4o_mini': {'doc_mrr_evaluator': 0.7834947049924357,\n",
       "  'doc_rec_evaluator': 0.9122541603630863,\n",
       "  'map': 0.7839544461253997},\n",
       " 'model_mini_lm_docs_llama': {'doc_mrr_evaluator': 0.7829803328290469,\n",
       "  'doc_rec_evaluator': 0.9113464447806354,\n",
       "  'map': 0.7834400739620109},\n",
       " 'model_distilbert_docs_4o_mini': {'doc_mrr_evaluator': 0.7919616742309635,\n",
       "  'doc_rec_evaluator': 0.9222390317700454,\n",
       "  'map': 0.7923861153134987},\n",
       " 'model_distilbert_docs_llama': {'doc_mrr_evaluator': 0.7912455874936968,\n",
       "  'doc_rec_evaluator': 0.9213313161875946,\n",
       "  'map': 0.791670028576232}}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_mrr_evaluator</th>\n",
       "      <th>doc_rec_evaluator</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_mini_lm_docs_4o_mini</th>\n",
       "      <td>0.783495</td>\n",
       "      <td>0.912254</td>\n",
       "      <td>0.783954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_mini_lm_docs_llama</th>\n",
       "      <td>0.782980</td>\n",
       "      <td>0.911346</td>\n",
       "      <td>0.783440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_distilbert_docs_4o_mini</th>\n",
       "      <td>0.791962</td>\n",
       "      <td>0.922239</td>\n",
       "      <td>0.792386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_distilbert_docs_llama</th>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.921331</td>\n",
       "      <td>0.791670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doc_mrr_evaluator  doc_rec_evaluator       map\n",
       "model_mini_lm_docs_4o_mini              0.783495           0.912254  0.783954\n",
       "model_mini_lm_docs_llama                0.782980           0.911346  0.783440\n",
       "model_distilbert_docs_4o_mini           0.791962           0.922239  0.792386\n",
       "model_distilbert_docs_llama             0.791246           0.921331  0.791670"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proje-m46awf8E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
